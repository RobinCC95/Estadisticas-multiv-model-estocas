---
title: "Practica III"
author: "Robinson Aldair Cuayal"
date: "2023-03-11"
output: word_document
lang: es-ES
toc: TRUE
---

\newpage

# Punto 1

El ejercicio en cuestión implica la realización de un análisis de regresión para determinar si existe
una relación entre el nivel de plomo en el suelo y la categoría del individuo, y si el nivel de plomo
en el suelo es un factor significativo para predecir los niveles altos de plomo en la sangre de los niños. 
Se proporcionan la hipótesis nula y la alternativa, así como los valores de p, la ecuación de regresión y 
las estadísticas relevantes. El objetivo principal es predecir los niveles altos de plomo en la sangre de los niños. 
Como primer paso, se va a almacenar la informacion de las tablas en un excel para luego ser cargado y convertido a un 
dataframe en R.

```{r}
library(readxl)
datos = data.frame(read_excel("dataset_ejer1.xlsx"))
dim(datos)
head(datos)
```
Con la carga de los datos, como segundo paso se implementa el modelo de regresion logistica. Cabe resaltar que 
es importante especificar el tipo de enlace en la modelación logística ya que afecta directamente la interpretación 
de los coeficientes del modelo y los resultados obtenidos.
```{r}
# Crear la regresión logística
modelo_logistico = glm(
  Categoria_del_Individuo ~ Nivel_plomo_suelo,
  data = datos,
  family = binomial(link = "logit")
)
#modelo general
summary(modelo_logistico)

# Obtener la razón de grados de probabilidad
coeficientes = coef(modelo_logistico)
razon_encontrada = exp(coeficientes["Nivel_plomo_suelo"])
razon_encontrada
# Compara la razón de grados de probabilidad contra la que obtuvieron los autores (14.25)
razon_autores = 14.25
# Realizar la prueba de significancia
summary(modelo_logistico)$coefficients["Nivel_plomo_suelo", "Pr(>|z|)"]

```

La razón de grados de probabilidad obtenida es de 1.002, lo que indica que por cada diez veces que aumenta el nivel de
plomo en la tierra, la proporción relativa de casos con respecto a los grupos de control aumenta en un 0.1. 
Este resultado difiere del obtenido por los autores del estudio (14.25).
El valor de p obtenido es $4.601328*10^{-07}$, lo que indica que el nivel de plomo en la tierra es un factor significativo para 
predecir los niveles altos de plomo en la sangre de los niños. \n
Las grafica del modelo es el siguiente
```{R}
library(ggplot2)
ggplot(data = datos, aes(x = Nivel_plomo_suelo, y = Categoria_del_Individuo)) +
  geom_point(aes(color = as.factor(Categoria_del_Individuo)), shape = 1) +
  stat_function(fun = function(x){predict(modelo_logistico,
                                          newdata = data.frame(Nivel_plomo_suelo = x),
                                          type = "response")}) +
  theme_bw() +
  labs(title = "Regresión logística",
       y = "Probabilidad plomo en niños") +
  theme(legend.position = "none")

```

## Preguntas

a) La variable dependiente es la "Categoria_del_Individuo".
b) La variable independiente es la "Nivel_plomo_suelo".
c) Hipótesis nula: No hay relación entre el nivel de plomo en el suelo y la categoría del individuo. \n
Hipótesis alternativa: Existe una relación entre el nivel de plomo en el suelo y la categoría del individuo.
d) La hipótesis nula es rechazada debido a que el valor de p obtenido $4.601328*10^{-07}$ es menor al nivel de 
significancia del 0.05 establecido. Esto indica que hay suficiente evidencia para concluir que el nivel de plomo 
en el suelo es un factor significativo para predecir los niveles altos de plomo en la sangre de los niños.
e) El objetivo más relevante es predecir los niveles altos de plomo en la sangre de los niños, ya que esto puede 
tener graves consecuencias en su salud. Aunque la estimación de parámetros es importante para comprender la relación 
entre las variables, la predicción tiene una mayor importancia práctica.
f) La población muestreada son niños expuestos al plomo en la ciudad donde se realizó el estudio.
g) La población objetivo son todos los niños expuestos al plomo, independientemente de su ubicación geográfica.
h) La variable "Nivel_plomo_suelo" está relacionada directamente con la "Categoria_del_Individuo", ya que aumentos en la 
primera variable son predictores de una mayor proporción de casos en la segunda variable,
al examinar la significación estadística de los coeficientes de la regresión y de las variables incluidas al ser significativo y positivo.
Los datos no tienen una alta correlacion segun el Nab pero al tener los resultado del modelo de regresion logistica
hay que tener en cuenta el primer enunciado.
```{R}
r = cor(datos)
nab = 1-det(r)
nab
```
i) La ecuación de regresión es: $y = b0 + b1x$, donde "y" es la "Categoria_del_Individuo", "x" es la "Nivel_plomo_suelo", 
b0 es el intercepto y b1 es la pendiente. En este caso, la ecuación sería: 
$Categoria_del_Individuo = -1.516206 + 0.002743*Nivel_plomo_suelo$.
j) Para realizar otro analisis adicionando valores puede ser el del sexo que pueden tomar como masculino (1) y 
femenino (0).
k) La variable "Categoria_del_Individuo" es categórica binaria (0 para control y 1 para caso), mientras 
que la variable "Nivel_plomo_suelo" es cuantitativa. 
La razón de grados de probabilidad (también conocido como odds ratio) es una medida de la asociación 
entre dos eventos.
La variable sexo tambien es categórica binaria.
diferentes valores de la variable independiente.
l) Con base en el punto (j) donde se le puede dar valores de nuestra parte a la variable de sexo de los niños, 
se diseña el modelo modelo logistico para el siguiente analisis estadistico.
```{R}
#codigo modelo 2 aqui
```


# Punto 2

En primer lugar, se realiza la carga de los datos que se almacenaron previamente en una hoja excel, para
luego convertir a un dataframe:
```{r}
library(readxl)
olmos <- data.frame(read_excel("dataset_ejer_2.xlsx"))
dim(olmos)
head(olmos)
```

## Preguntas

a) Realizar el analisis de componenetes principales (PCA) completo con gráficos de cargas.

Antes de realizar un analisis por PCA, hay que tener en cuenta que debe haber una
alta correlacion entre los datos, porque de lo contrario no tiene sentido realizar
este analisis.
```{R}
r = det(cor(olmos))
nab = 1-r
nab
```

Como se puede observar hay una alta correlacion de los datos ya que el 
$nab = 0.999 -> aprox= 1$.
Ya con esta prueba es factible hacer este analisis de PCA. Se comienza con la creacion del modelo PCA, 
donde esta informacion relevante como varianza y correlacion.
```{R}
# Análisis de componentes principales
acp = princomp(olmos, cor = TRUE)
summary(acp)
#grafico de cargas de las variables
vector_propios = acp$loadings
#cambio de signo
acp$loadings[,2] = -acp$loadings[,2]
acp$scores[,2] = -acp$scores[,2]
#correlacion entre las componentes y las variables
desviacion_stand = acp$sdev
correlacion = sweep(vector_propios[1:7,1:7],2, desviacion_stand, "*" )
round(correlacion,3)

```

Se realiza el grafico de cargas de en donde para identificar cuál variable tiene más contribución en el gráfico de cargas
circulares, se debe observar la distancia de cada círculo al origen central del gráfico. Por lo cual todas las variables
tienen un buen aporte de informacion.
```{R}
#grafico de cargas de las variables
library(MASS)
eqscplot(correlacion[,1:2], xlim=c(-1,1), ylim=c(-1,1), type = "n")
abline(h=0,v=0)
text(correlacion[,1:2],labels=colnames(olmos),cex=0.8)
symbols(0,0,circles=1, inches=FALSE, add=TRUE)
biplot(acp, cex=0.75)
```

b) Cuales variables presentan más similitud.

Segun la tabla, se observa que la variable con mayor similitud es X2 (diametro) y X4 (peso total), con un valor de 
correlación de 97%. Tambien con una correlacion del 96% se tiene relacion las siguientes parejas (X1,X2), (X4,X5)
```{R}
#Variable con mayor similitud
cor(olmos)
```

c) Cuantos componentes explican la mayor variabilidad de los datos.

Para conocer cuántos componentes explican la mayor variabilidad de los datos, se usa la función summary() sobre el 
objeto pca. La salida muestra que el componente 1 explica el 91.25% de la variabilidad. Tambien en el grafico de sedimentacion
se observo que era la unica componente al superar el 1, por lo cual solo se escoge esta componente.
```{R}
summary(acp)
```
Se realiza el grafico de sedimentacion en donde se escoge las variables que tengan una varianza mayor a 1.
```{R}
#calculo de los valores propios
val_propios = acp$sdev^2
plot(1:7, val_propios, type= "b", xlab="componentess", ylab="varianza", 
main = "sedimentacion")
```

d) Que grupos de individuos presentan más similitud.

Para conocer los grupos de individuos que presentan mayor similitud se realiza la  grafica de dispersion de los individuos
y las variables. Segun el grafico se encuentra dos grupos divididos por una linea vertical en el punto 0.
El gráfico muestra que las dos observaciones están relativamente cercanas entre sí.
```{R}
library(psych)
acp_varimax = principal(olmos, nfactors = 2, rotate = "varimax",scores = TRUE)
round(cor(olmos, acp_varimax$scores[,1:2]),3)#tabla de comunidades
biplot(acp_varimax, labels = rownames(olmos), cex= 0.75,  main = "Grafico de dispersion")
```

e) Realizar un análisis de regresión lineal del componente 1 y sus respectivas variables de carga.

El siguiente grafico ayuda a ver el aporte que tienen cada individuo al componenetes 1.
```{R}
plot(acp$scores[,1], type= "n",)
abline(h=0, v= 0)
text(acp$scores[,1], 
labels= rownames(olmos), cex=0.8)
```

Para realizar el análisis de regresión lineal del componente 1 y su respectiva variables de carga, 
se crea un data frame con las dos columnas.
```{R}
#para la variable X1
datos_regresion = data.frame(acp$scores[,1], olmos$X1)
names(datos_regresion) = c('cargasX1', 'datosX1')
model_X1 = lm(datos_regresion$datosX1~datos_regresion$cargasX1)  
summary(model_X1)
#para la varible X2
datos_regresion2 = data.frame(acp$scores[,1], olmos$X2)
names(datos_regresion2) = c('cargasX1', 'datosX2')
model_X2 = lm(datos_regresion2$datosX2~datos_regresion2$cargasX1)  
summary(model_X2)
#para la varible X3
datos_regresion3 = data.frame(acp$scores[,1], olmos$X3)
names(datos_regresion3) = c('cargasX1', 'datosX3')
model_X3 = lm(datos_regresion3$datosX3~datos_regresion3$cargasX1)  
summary(model_X3)
```
Como se puede ver hay una alta correlacion entre los datos y el nuevo componente 1 PCA, el cual explica el 91% de los datos, 
por lo cual cuando se realiza regresion lineal con cada una de las variables de los datos da una alta correlacion y con un 
$R^2$ mayor al 89% a excepcion del X3 que da de un 81%. Solo se hizo modelos lm() hasta la variable 3 los modelos. 
En conclusión, el análisis de regresión lineal del primer componente principal y sus respectivas variables de carga 
permite explicar en gran medida la variabilidad de los datos y evidencia la influencia de la variables X1 en la 
formación del componente. La carga de una variable en un componente principal indica cuánto contribuye esa variable a 
la varianza explicada por ese componente. Al realizar la regresión lineal, puedes analizar cómo la variable original 
está relacionada con el componente principal y si existe una relación lineal significativa entre ellas.

# Punto 3

Para la solucion del ejercicio de distancias entre los datos y correlacion, primero se carga los datos a un excel para ser
convertido a un dataframe:
```{r}
library(readxl)
datos = data.frame(read_excel("dataset_ejer_3.xlsx"))
datos
```

## Preguntas

a. Calcular la covarianza.

La covarianza es una medida de cómo dos variables se mueven en relación entre sí. Un valor positivo indica que las 
variables se mueven de manera similar, mientras que un valor negativo indica que las variables se mueven de manera opuesta.
En este caso, la matriz de covarianza muestra que la mayoría de las variables están positivamente correlacionadas entre sí.

```{R}
# Calcular la covarianza
covarianza = cov(datos)
covarianza
```

b. Calcular la matriz de correlación.

La matriz de correlación es una medida de la fuerza y dirección de la relación lineal entre dos variables.
Los valores van desde -1 (correlación negativa perfecta) a 1 (correlación positiva perfecta), 
con 0 indicando que no hay relación. Los datos muestran una fuerte correlación positiva entre X6(O3) y X7(HC) y una 
correlacion alta correlacion negativa entre X2(Radiación solar) y X5(N02), mientras que las otras variables no 
tienen una correlación tan fuerte. En el Dispersograma se puede ver como un especie de linealidad de los datos.

```{R}
# Calcular la matriz de correlación
correlacion = cor(datos)
correlacion

#Dispersograma
plot(datos)
```

c. Calcular las distancias euclidianas y mahalanobis

La distancia euclidiana es una medida de la distancia entre dos puntos en un espacio multidimensional. 
En este caso, muestra la distancia entre las 10 filas de la tabla en un espacio de 7 dimensiones. 
La distancia mahalanobis es similar, pero tiene en cuenta la covarianza entre las variables. La distancia euclidiana 
y mahalanobis producen resultados diferentes en este conjunto de datos pero de la misma forma sirven para 
clasificar un conjunto de datos.

```{R}
# Media 
datos_media = colMeans(datos)

# Calcular las distancias euclidianas
dist_euclidianas_indiv = dist(datos, method = "euclidean")
dist_euclidianas_indiv

# Calcular las distancias mahalanobis
dist_mahalanobis = sqrt(mahalanobis(datos,datos_media,covarianza))
dist_mahalanobis
```

Para la distancia con uso de la media:
```{R}
# Calcular las distancias euclidianas
dist_euclidianas_media = dist(rbind(datos_media,datos))
dist_euclidianas_media

# Calcular las distancias mahalanobis
dist_mahalanobis_media = apply(datos, 1, function(xi) {
  sqrt(mahalanobis(xi, datos_media, covarianza))
})
dist_mahalanobis_media
```

# Punto 4

Para este ejercicio se pide un hacer una regresion logistica, por ello se empieza replicando los datos de la 
tabla.
```{r}
# Desempeño_escolar : deficiente -> 0   satisfactorio -> 1
# Estado nutricional : deficiente -> 0   bueno -> 1

desemp_esc = c(rep(0,105), rep(1,80),rep(0,15), rep(1,300))
estado_nutric = c(rep(0,105), rep(0,80),rep(1,15), rep(1,300))
datos = data.frame(desemp_esc, estado_nutric)
table(datos)
```

# Punto 5

```{r}
cat('hola')
```